# Cardinality Estimation

Этот репозиторий содержит реализации вероятностных структур данных на Go для решения cardinality estimation задачи.

## Что такое Cardinality Estimation?

Cardinality estimation — это методы приближённого подсчёта количества уникальных элементов (кардинальности) в больших
наборах данных. Решает задачи анализа уникальных посещений, подсчёта distinct-значений в БД, мониторинга сетевого трафика
и другие, где точный подсчёт требует неприемлемо много памяти.

## Реализованные структуры данных

* [**LogLog**](loglog) — вероятностный алгоритм, оценивающий кардинальность по максимальным ведущим нулям в хешах элементов.
* [**HyperLogLog**](hyperloglog) — улучшение LogLog с повышенной точностью за счёт использования среднего гармонического.
* [**HyperBitBit**](hyperbitbit) — компактная вариация HyperLogLog, сочетающая битовые карты для малых кардинальностей и
  вероятностное оценивание для больших.
* [**Linear Counting**](linear_counting) — простой алгоритм на основе битовой карты, эффективен для малых и средних множеств.

## Особенности реализации

Все реализации разработаны с учётом требований highload-систем и многопоточной среды:

* Отсутствие блокировок, используются только atomic операции
  * Высокая производительность при параллельных чтении/записи
* Минимизация потребления памяти и аллокаций
* Использование SIMD операций (где возможно)

### Инициализация

Каждая пакет содержит структуру `Config`, позволяющую гибко настроить структуру.
Пример [`Config`](hyperloglog/config.go). Общим у конфигов является возможность задать:

* Нужную хэш-функцию (обязательный параметр)
* Предполагаемое максимальное количество элементов в множестве (задаётся верхняя граница с запасом)
* Точность или допустимая вероятность коллизий
* Режим поддержки конкурентных операций (отключён по умолчанию)
* Параметр [`MetricsWriter`](metrics.go) для записи метрик

### Сериализация состояния

Все структуры поддерживают сериализацию внутреннего состояния через `io.WriterTo` и восстановление из `io.ReaderFrom`.
Это решает проблему "холодного старта" — позволяет сохранять накопленную статистику между запусками системы и быстро
восстанавливать работу без потери точности оценок на старте.

Предполагаемое использование - периодическая запись состояния в хранилище (например, в файл или облако) и чтение на старте.
При включённом режиме поддержки конкурентных операций, эти операции будут выполняться с защитой от гонок данных.

### Единый интерфейс

Все реализации имеют общий интерфейс [`Estimator`](interface.go), позволяющий:

- Добавлять элемент
- Оценить кардинальность всех добавленных элементов
- Очищать структуру

Это обеспечивает взаимозаменяемость структур данных без модификации кода, использующего их.
Позволяет легко сравнивать и выбирать подходящий алгоритм для конкретной задачи.

### Мониторинг и метрики

В каждую реализацию, через `Config` структуру, можно передать реализацию [`MetricsWriter`](metrics.go), которая будет писать
метрики:

- Сколько элементов добавлено
- Гистограмму кардинальности множества

Это позволит решить проблему "чёрного ящика" - метрики помогут оценить оптимально настроена структура и настроить её
точнее при необходимости.

Имеется коробочная реализация [Prometheus](../metrics/prometheus/cardinality.go) TSDB. При необходимости можно написать
собственную реализацию для своей TSDB (например VictoriaMetrics).

## Примеры применения

* Анализ уникальных посетителей веб-сайтов и мобильных приложений
* Мониторинг и обнаружение аномалий в сетевом трафике (например, DDoS-атаки)
* Оптимизация запросов к базам данных (оценка DISTINCT-значений)
* Стриминговые платформы — подсчёт уникальных зрителей
* Большие данные — быстрая оценка размеров множеств в процессах ETL

## Заключение

Представленные реализации могут помочь оценить кардинальность множеств там, где не справятся более примитивные способы
(например хэш-таблицы). Используйте метрики для настройки и всегда будьте в курсе, какие данные поступают в вашу систему.
