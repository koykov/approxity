# Frequency Estimation

Этот репозиторий содержит реализации вероятностных структур данных на Go для решения frequency estimation задачи.

## Что такое Frequency Estimation?

Frequency estimation (оценка частоты) — это задача подсчёта или оценки количества вхождений элементов в потоке данных.
Она решает такие проблемы, как:

* определение "горячих" (часто встречающихся) элементов
* фильтрация редких данных
* оптимизация кэширования (например, в LFU-кэшах)

## Реализованные структуры

* [**Count-Min Sketch**](cusketch) — вероятностная структура, дающая верхнюю оценку частоты элемента с заданной точностью.
* [**Conservative Update Sketch**](cusketch) — модификация Count-Min Sketch, уменьшающая ошибку за счёт консервативных
  обновлений (обновляются только минимальные элементы).
* [**Count Sketch**](countsketch) — структура, которая в отличие от Count-Min Sketch может давать как верхние,
  так и нижние оценки частот.
* [**TinyLFU**](tinylfu) — адаптивная структура для оценки частот, оптимизированная для использования в кэшах.
* [**TinyLFU (EWMA version)**](tinylfu_ewma) — вариация TinyLFU с экспоненциальным взвешенным скользящим средним
  для адаптации к изменениям в распределении частот. На эту реализацию рекомендую обратить особое внимание, она намного
  более оптимальна, чем классический `TinyLFU`.

## Особенности реализации

Все структуры разработаны с учётом работы в высоконагруженных многопоточных средах:

* Использование atomic операций вместо тяжёлых блокировок
* Минимизация потребления памяти/аллокаций
* Использование SIMD инструкций для ускорения вычислений

### Инициализация

Каждая пакет содержит структуру `Config`, позволяющую гибко настроить структуру.
Пример [`Config`](cmsketch/config.go). Общим у конфигов является возможность задать:

* Нужную хэш-функцию (обязательный параметр)
* Параметры Confidence/Epsilon для контроля точности оценки и допустимого уровня ошибок
* Флаг Compact для использования 32-битных счетчиков
* Режим поддержки конкурентных операций (отключён по умолчанию)
* Параметр [`MetricsWriter`](metrics.go) для записи метрик

### Сериализация состояния

Структуры поддерживают запись внутреннего состояния через `io.WriterTo` и восстановление через `io.ReaderFrom`.
Это решает проблему холодного старта — после перезапуска системы можно продолжить сбор статистики с сохранённых данных,
а не начинать с нуля.

### Единый интерфейс

Все реализации соответствуют единому интерфейсу [`Estimator`](interface.go), который позволяет:

* Добавлять элемент
* Оценить частоту конкретного элемента
* Очищать структуру

Это позволяет легко заменять одну структуру на другую без изменения кода приложения и даёт гибкость в выборе
оптимального алгоритма для конкретной задачи.

Некоторые структуры реализуют `SignedEstimator` и `PreciseEstimator` (см [interface.go](interface.go)) из-за особенностей
реализации - возможность выдавать отрицательные и дробные оценки частоты.

### Мониторинг и метрики

Структура `Config` позволяет передать реализацию [`MetricsWriter`](metrics.go), которая будет писать метрики:

* Сколько элементов добавлено
* Гистограмму частот запрашиваемых элементов

Аналогично интерфейсу `Estimator`, `MetricsWriter` имеет также варианты `SignedMetricsWriter` и `PreciseMetricsWriter`
(см [metrics.go](metrics.go)).

Применение метрик позволяет решить проблему "чёрного ящика", всегда можно оценить насколько эффективно структура
справляется с задачей и при необходимости настроить её более оптимально.

Имеется коробочная реализация [Prometheus](../metrics/prometheus/frequency.go) TSDB. При необходимости можно написать
собственную реализацию для своей TSDB (например VictoriaMetrics).

## Примеры применения

* Оптимизация кэширования (LFU-кэши)
* Анализ сетевого трафика (выявление частых запросов)
* Фильтрация спама (определение часто встречающихся шаблонов)
* Рекомендательные системы (выявление популярного контента)
* Балансировка нагрузки (определение "горячих" ключей в распределённых системах)

## Заключение

Представленные вероятностные структуры данных предлагают эффективные решения для оценки частот элементов в потоковых данных.
Их особенности делают их особо полезными в высоконагруженных системах, где важны как производительность,
так и минимальное использование ресурсов. Возможность легкого переключения между разными реализациями позволяет выбрать
оптимальный вариант для конкретного сценария использования.
